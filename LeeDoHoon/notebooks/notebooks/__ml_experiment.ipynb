{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ac6a15",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f96bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0838a5c",
   "metadata": {},
   "source": [
    "# 데이터 로드/확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5f2c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/processed/kkbox_train_feature_v1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de362c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(860966, 90)\n",
      "is_churn\n",
      "0    0.905399\n",
      "1    0.094601\n",
      "Name: proportion, dtype: Float64\n"
     ]
    }
   ],
   "source": [
    "assert \"msno\" in df.columns and \"is_churn\" in df.columns\n",
    "print(df.shape)\n",
    "print(df[\"is_churn\"].value_counts(normalize=True).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5192c920",
   "metadata": {},
   "source": [
    "# Train / Valid / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ba1eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churn rate: 0.09460141104009451 0.09459909404158116 0.09459909404158116\n",
      "(602676, 88) (129145, 88) (129145, 88)\n"
     ]
    }
   ],
   "source": [
    "# 1) test 15%\n",
    "trainval_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify=df[\"is_churn\"],\n",
    ")\n",
    "\n",
    "# 2) valid 15% (전체의 15%가 되도록 0.15/0.85)\n",
    "valid_ratio_in_trainval = 0.15 / 0.85\n",
    "train_df, valid_df = train_test_split(\n",
    "    trainval_df,\n",
    "    test_size=valid_ratio_in_trainval,\n",
    "    random_state=42,\n",
    "    stratify=trainval_df[\"is_churn\"],\n",
    ")\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in [\"msno\", \"is_churn\"]]\n",
    "\n",
    "X_train, y_train = train_df[feature_cols], train_df[\"is_churn\"].astype(int)\n",
    "X_valid, y_valid = valid_df[feature_cols], valid_df[\"is_churn\"].astype(int)\n",
    "X_test,  y_test  = test_df[feature_cols],  test_df[\"is_churn\"].astype(int)\n",
    "\n",
    "print(\"churn rate:\", y_train.mean(), y_valid.mean(), y_test.mean())\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32581969",
   "metadata": {},
   "source": [
    "# datetime/period 컬럼을 “피처로 쓰는” 변환 함수\n",
    "- 원본 datetime/period는 모델이 싫어하니까 파생 숫자 피처로 바꿔서 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f5bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "\n",
    "def add_time_features(\n",
    "    X: pd.DataFrame,\n",
    "    dt_col: str = \"registration_init_time\",\n",
    "    period_col: str = \"registration_month\",\n",
    ") -> pd.DataFrame:\n",
    "    X = X.copy()\n",
    "\n",
    "    # datetime -> year/month/day\n",
    "    if dt_col in X.columns:\n",
    "        dt = pd.to_datetime(X[dt_col], errors=\"coerce\")\n",
    "        X[f\"{dt_col}_year\"] = dt.dt.year.astype(\"Int16\")\n",
    "        X[f\"{dt_col}_month\"] = dt.dt.month.astype(\"Int8\")\n",
    "        X[f\"{dt_col}_day\"] = dt.dt.day.astype(\"Int8\")\n",
    "        X = X.drop(columns=[dt_col])\n",
    "\n",
    "    # period[M] -> year/month\n",
    "    if period_col in X.columns:\n",
    "        p = X[period_col]\n",
    "        if not isinstance(p.dtype, pd.PeriodDtype):\n",
    "            p = p.astype(\"period[M]\")\n",
    "        X[f\"{period_col}_year\"] = p.dt.year.astype(\"Int16\")\n",
    "        X[f\"{period_col}_month\"] = p.dt.month.astype(\"Int8\")\n",
    "        X = X.drop(columns=[period_col])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b302a9f3",
   "metadata": {},
   "source": [
    "# 시간 피처 변환 적용 + drop 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96611a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (602676, 88) after: (602676, 91)\n",
      "False False\n"
     ]
    }
   ],
   "source": [
    "X_train2 = add_time_features(X_train)\n",
    "X_valid2 = add_time_features(X_valid)\n",
    "X_test2  = add_time_features(X_test)\n",
    "\n",
    "print(\"before:\", X_train.shape, \"after:\", X_train2.shape)\n",
    "\n",
    "# 원본 컬럼이 사라졌는지 확인\n",
    "print(\"registration_init_time\" in X_train2.columns, \"registration_month\" in X_train2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d56ab8",
   "metadata": {},
   "source": [
    "# 컬럼 분리 + preprocess 정의\n",
    "- LR은 scaler 포함\n",
    "- LGBM은 scaler 불필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a165722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num: 90 cat: 1 cat example: ['gender']\n"
     ]
    }
   ],
   "source": [
    "from pandas.api.types import is_object_dtype, is_string_dtype\n",
    "\n",
    "def split_cols(X: pd.DataFrame):\n",
    "    cat_cols = [\n",
    "        c for c in X.columns\n",
    "        if (is_object_dtype(X[c])\n",
    "            or is_string_dtype(X[c])\n",
    "            or isinstance(X[c].dtype, pd.CategoricalDtype))\n",
    "    ]\n",
    "    num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "    return num_cols, cat_cols\n",
    "\n",
    "num_cols, cat_cols = split_cols(X_train2)\n",
    "print(\"num:\", len(num_cols), \"cat:\", len(cat_cols), \"cat example:\", cat_cols[:10])\n",
    "\n",
    "def make_preprocess(num_cols, cat_cols, *, for_lr: bool):\n",
    "    num_steps = [(\"imputer\", SimpleImputer(strategy=\"median\"))]\n",
    "    if for_lr:\n",
    "        num_steps.append((\"scaler\", StandardScaler(with_mean=False)))  # sparse 안전\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", Pipeline(num_steps), num_cols),\n",
    "            (\"cat\", Pipeline([\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "            ]), cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafe2e0a",
   "metadata": {},
   "source": [
    "# 공통 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c40f1742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_binary(y_true, y_proba, threshold=0.5, prefix=\"\"):\n",
    "    roc = roc_auc_score(y_true, y_proba)\n",
    "    pr  = average_precision_score(y_true, y_proba)\n",
    "\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(f\"{prefix}ROC-AUC: {roc:.6f} | PR-AUC(AP): {pr:.6f} | thr={threshold}\")\n",
    "    print(f\"{prefix}Confusion matrix:\\n{cm}\")\n",
    "    print(f\"{prefix}Classification report:\\n{classification_report(y_true, y_pred, digits=4)}\")\n",
    "\n",
    "    return roc, pr, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f7cf25",
   "metadata": {},
   "source": [
    "# Logistic Regression 학습/평가 (빠른 루트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9e364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/project-2nd/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR valid] ROC-AUC: 0.966573 | PR-AUC(AP): 0.839794 | thr=0.5\n",
      "[LR valid] Confusion matrix:\n",
      "[[111510   5418]\n",
      " [  1498  10719]]\n",
      "[LR valid] Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9867    0.9537    0.9699    116928\n",
      "           1     0.6642    0.8774    0.7561     12217\n",
      "\n",
      "    accuracy                         0.9464    129145\n",
      "   macro avg     0.8255    0.9155    0.8630    129145\n",
      "weighted avg     0.9562    0.9464    0.9497    129145\n",
      "\n",
      "[LR test ] ROC-AUC: 0.966887 | PR-AUC(AP): 0.842084 | thr=0.5\n",
      "[LR test ] Confusion matrix:\n",
      "[[111540   5388]\n",
      " [  1454  10763]]\n",
      "[LR test ] Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9871    0.9539    0.9702    116928\n",
      "           1     0.6664    0.8810    0.7588     12217\n",
      "\n",
      "    accuracy                         0.9470    129145\n",
      "   macro avg     0.8268    0.9175    0.8645    129145\n",
      "weighted avg     0.9568    0.9470    0.9502    129145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/project-2nd/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9668869425747473,\n",
       " 0.8420841002521133,\n",
       " array([[111540,   5388],\n",
       "        [  1454,  10763]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_lr = make_preprocess(num_cols, cat_cols, for_lr=True)\n",
    "\n",
    "X_train_t = preprocess_lr.fit_transform(X_train2)\n",
    "X_valid_t = preprocess_lr.transform(X_valid2)\n",
    "X_test_t  = preprocess_lr.transform(X_test2)\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    max_iter=3000,\n",
    "    class_weight=\"balanced\",\n",
    "    solver=\"saga\",\n",
    "    # n_jobs=-1,\n",
    ")\n",
    "\n",
    "lr.fit(X_train_t, y_train)\n",
    "\n",
    "p_valid = lr.predict_proba(X_valid_t)[:, 1]\n",
    "p_test  = lr.predict_proba(X_test_t)[:, 1]\n",
    "\n",
    "eval_binary(y_valid, p_valid, prefix=\"[LR valid] \")\n",
    "eval_binary(y_test,  p_test,  prefix=\"[LR test ] \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f2969",
   "metadata": {},
   "source": [
    "# LightGBM 학습/평가 (early stopping 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a692e2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 9.570666853755219\n",
      "[LightGBM] [Info] Number of positive: 57014, number of negative: 545662\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 16815\n",
      "[LightGBM] [Info] Number of data points in the train set: 602676, number of used features: 93\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.094601 -> initscore=-2.258703\n",
      "[LightGBM] [Info] Start training from score -2.258703\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's auc: 0.988414\tvalid_0's binary_logloss: 0.12475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/project-2nd/lib/python3.12/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/project-2nd/lib/python3.12/site-packages/sklearn/utils/validation.py:2691: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM valid] ROC-AUC: 0.988414 | PR-AUC(AP): 0.923838 | thr=0.5\n",
      "[LGBM valid] Confusion matrix:\n",
      "[[112672   4256]\n",
      " [   888  11329]]\n",
      "[LGBM valid] Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9922    0.9636    0.9777    116928\n",
      "           1     0.7269    0.9273    0.8150     12217\n",
      "\n",
      "    accuracy                         0.9602    129145\n",
      "   macro avg     0.8595    0.9455    0.8963    129145\n",
      "weighted avg     0.9671    0.9602    0.9623    129145\n",
      "\n",
      "[LGBM test ] ROC-AUC: 0.988967 | PR-AUC(AP): 0.928185 | thr=0.5\n",
      "[LGBM test ] Confusion matrix:\n",
      "[[112674   4254]\n",
      " [   888  11329]]\n",
      "[LGBM test ] Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9922    0.9636    0.9777    116928\n",
      "           1     0.7270    0.9273    0.8150     12217\n",
      "\n",
      "    accuracy                         0.9602    129145\n",
      "   macro avg     0.8596    0.9455    0.8964    129145\n",
      "weighted avg     0.9671    0.9602    0.9623    129145\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.988966981410978,\n",
       " 0.9281846271009779,\n",
       " array([[112674,   4254],\n",
       "        [   888,  11329]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_lgbm = make_preprocess(num_cols, cat_cols, for_lr=False)\n",
    "\n",
    "X_train_t = preprocess_lgbm.fit_transform(X_train2)\n",
    "X_valid_t = preprocess_lgbm.transform(X_valid2)\n",
    "X_test_t  = preprocess_lgbm.transform(X_test2)\n",
    "\n",
    "pos = float(y_train.sum())\n",
    "neg = float((y_train == 0).sum())\n",
    "scale_pos_weight = neg / pos if pos > 0 else 1.0\n",
    "print(\"scale_pos_weight:\", scale_pos_weight)\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(\n",
    "    n_estimators=5000,\n",
    "    learning_rate=0.02,\n",
    "    num_leaves=63,\n",
    "    min_child_samples=50,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    ")\n",
    "\n",
    "lgbm.fit(\n",
    "    X_train_t, y_train,\n",
    "    eval_set=[(X_valid_t, y_valid)],\n",
    "    eval_metric=\"auc\",\n",
    "    callbacks=[lgb.early_stopping(200, verbose=True)],\n",
    ")\n",
    "\n",
    "p_valid_lgbm = lgbm.predict_proba(X_valid_t)[:, 1]\n",
    "p_test_lgbm  = lgbm.predict_proba(X_test_t)[:, 1]\n",
    "\n",
    "eval_binary(y_valid, p_valid_lgbm, prefix=\"[LGBM valid] \")\n",
    "eval_binary(y_test,  p_test_lgbm,  prefix=\"[LGBM test ] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12cedbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to artifacts/\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"artifacts\").mkdir(exist_ok=True)\n",
    "\n",
    "joblib.dump({\"model\": lr, \"preprocess\": preprocess_lr}, \"artifacts/lr.joblib\")\n",
    "joblib.dump({\"model\": lgbm, \"preprocess\": preprocess_lgbm}, \"artifacts/lgbm.joblib\")\n",
    "\n",
    "print(\"saved to artifacts/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d391fff",
   "metadata": {},
   "source": [
    "# XGBoost, CatBoost, RandomForest 모델을 위한 공통 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfc04061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.570666853755219"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_common = make_preprocess(num_cols, cat_cols, for_lr=False)\n",
    "\n",
    "X_train_t = preprocess_common.fit_transform(X_train2)\n",
    "X_valid_t = preprocess_common.transform(X_valid2)\n",
    "X_test_t  = preprocess_common.transform(X_test2)\n",
    "\n",
    "pos = float(y_train.sum())\n",
    "neg = float((y_train == 0).sum())\n",
    "scale_pos_weight = neg / pos if pos > 0 else 1.0\n",
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245ce684",
   "metadata": {},
   "source": [
    "# XGBoost 학습/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0b920ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b8486c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGB valid] ROC-AUC: 0.988489 | PR-AUC(AP): 0.931125 | thr=0.5\n",
      "[XGB valid] Confusion matrix:\n",
      "[[112798   4130]\n",
      " [   889  11328]]\n",
      "[XGB valid] Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9922    0.9647    0.9782    116928\n",
      "           1     0.7328    0.9272    0.8186     12217\n",
      "\n",
      "    accuracy                         0.9611    129145\n",
      "   macro avg     0.8625    0.9460    0.8984    129145\n",
      "weighted avg     0.9676    0.9611    0.9631    129145\n",
      "\n",
      "[XGB test ] ROC-AUC: 0.989018 | PR-AUC(AP): 0.934766 | thr=0.5\n",
      "[XGB test ] Confusion matrix:\n",
      "[[112755   4173]\n",
      " [   888  11329]]\n",
      "[XGB test ] Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9922    0.9643    0.9781    116928\n",
      "           1     0.7308    0.9273    0.8174     12217\n",
      "\n",
      "    accuracy                         0.9608    129145\n",
      "   macro avg     0.8615    0.9458    0.8977    129145\n",
      "weighted avg     0.9675    0.9608    0.9629    129145\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9890180685800413,\n",
       " 0.9347664053598701,\n",
       " array([[112755,   4173],\n",
       "        [   888,  11329]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators=5000,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    early_stopping_rounds=200,\n",
    ")\n",
    "\n",
    "xgb_clf.fit(\n",
    "    X_train_t, y_train,\n",
    "    eval_set=[(X_valid_t, y_valid)],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "p_valid_xgb = xgb_clf.predict_proba(X_valid_t)[:, 1]\n",
    "p_test_xgb  = xgb_clf.predict_proba(X_test_t)[:, 1]\n",
    "\n",
    "eval_binary(y_valid, p_valid_xgb, prefix=\"[XGB valid] \")\n",
    "eval_binary(y_test,  p_test_xgb,  prefix=\"[XGB test ] \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d590baf",
   "metadata": {},
   "source": [
    "# CatBoost 학습/평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fada0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a754c8",
   "metadata": {},
   "source": [
    "## 1) Period/Datetime 처리 (CatBoost용: 문자열/카테고리로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02332345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_catboost_df(\n",
    "    X: pd.DataFrame,\n",
    "    *,\n",
    "    dt_col: str = \"registration_init_time\",\n",
    "    period_col: str = \"registration_month\",\n",
    ") -> pd.DataFrame:\n",
    "    X = X.copy()\n",
    "\n",
    "    # datetime -> 문자열 카테고리(또는 파생 피처). 여기선 파생으로 추천.\n",
    "    if dt_col in X.columns:\n",
    "        dt = pd.to_datetime(X[dt_col], errors=\"coerce\")\n",
    "        X[f\"{dt_col}_year\"] = dt.dt.year.astype(\"Int16\")\n",
    "        X[f\"{dt_col}_month\"] = dt.dt.month.astype(\"Int8\")\n",
    "        X[f\"{dt_col}_day\"] = dt.dt.day.astype(\"Int8\")\n",
    "        X = X.drop(columns=[dt_col])\n",
    "\n",
    "    # period[M] -> 문자열 카테고리로 변환 (\"2015-01\" 같은 형태)\n",
    "    if period_col in X.columns:\n",
    "        p = X[period_col]\n",
    "        if isinstance(p.dtype, pd.PeriodDtype):\n",
    "            X[period_col] = p.astype(str)        # \"2015-01\"\n",
    "        else:\n",
    "            # 혹시 object로 들어왔어도 방어적으로 처리\n",
    "            X[period_col] = p.astype(\"string\")\n",
    "\n",
    "        # catboost가 확실히 categorical로 보게끔 category로 바꿔도 됨(선택)\n",
    "        X[period_col] = X[period_col].astype(\"category\")\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d6ba9",
   "metadata": {},
   "source": [
    "## 2) CatBoost 입력 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d094e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat cols: 2\n",
      "example: ['gender', 'registration_month']\n"
     ]
    }
   ],
   "source": [
    "X_train_cb = prep_catboost_df(X_train)\n",
    "X_valid_cb = prep_catboost_df(X_valid)\n",
    "X_test_cb  = prep_catboost_df(X_test)\n",
    "\n",
    "# categorical 컬럼 찾기: object / category / string\n",
    "cat_cols_cb = [\n",
    "    c for c in X_train_cb.columns\n",
    "    if (X_train_cb[c].dtype == \"object\"\n",
    "        or pd.api.types.is_string_dtype(X_train_cb[c])\n",
    "        or isinstance(X_train_cb[c].dtype, pd.CategoricalDtype))\n",
    "]\n",
    "\n",
    "cat_col_idx = [X_train_cb.columns.get_loc(c) for c in cat_cols_cb]\n",
    "\n",
    "print(\"cat cols:\", len(cat_cols_cb))\n",
    "print(\"example:\", cat_cols_cb[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "479252e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.9614759\tbest: 0.9614759 (0)\ttotal: 191ms\tremaining: 15m 53s\n",
      "200:\ttest: 0.9876067\tbest: 0.9876067 (200)\ttotal: 23.6s\tremaining: 9m 23s\n",
      "400:\ttest: 0.9881368\tbest: 0.9881368 (400)\ttotal: 46.1s\tremaining: 8m 48s\n",
      "600:\ttest: 0.9884856\tbest: 0.9884856 (600)\ttotal: 1m 8s\tremaining: 8m 24s\n",
      "800:\ttest: 0.9886492\tbest: 0.9886499 (794)\ttotal: 1m 31s\tremaining: 8m\n",
      "1000:\ttest: 0.9887249\tbest: 0.9887262 (995)\ttotal: 1m 54s\tremaining: 7m 37s\n",
      "1200:\ttest: 0.9887681\tbest: 0.9887682 (1181)\ttotal: 2m 17s\tremaining: 7m 15s\n",
      "1400:\ttest: 0.9887968\tbest: 0.9887968 (1400)\ttotal: 2m 40s\tremaining: 6m 52s\n",
      "1600:\ttest: 0.9888190\tbest: 0.9888208 (1587)\ttotal: 3m 3s\tremaining: 6m 29s\n",
      "1800:\ttest: 0.9888303\tbest: 0.9888354 (1696)\ttotal: 3m 26s\tremaining: 6m 7s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.9888354481\n",
      "bestIteration = 1696\n",
      "\n",
      "Shrink model to first 1697 iterations.\n",
      "[CAT valid] ROC-AUC: 0.988835 | PR-AUC(AP): 0.934152 | thr=0.5\n",
      "[CAT valid] Confusion matrix:\n",
      "[[115603   1325]\n",
      " [  1859  10358]]\n",
      "[CAT valid] Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9842    0.9887    0.9864    116928\n",
      "           1     0.8866    0.8478    0.8668     12217\n",
      "\n",
      "    accuracy                         0.9753    129145\n",
      "   macro avg     0.9354    0.9183    0.9266    129145\n",
      "weighted avg     0.9749    0.9753    0.9751    129145\n",
      "\n",
      "[CAT test ] ROC-AUC: 0.989190 | PR-AUC(AP): 0.937565 | thr=0.5\n",
      "[CAT test ] Confusion matrix:\n",
      "[[115679   1249]\n",
      " [  1821  10396]]\n",
      "[CAT test ] Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9845    0.9893    0.9869    116928\n",
      "           1     0.8927    0.8509    0.8713     12217\n",
      "\n",
      "    accuracy                         0.9762    129145\n",
      "   macro avg     0.9386    0.9201    0.9291    129145\n",
      "weighted avg     0.9758    0.9762    0.9760    129145\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9891901644053332,\n",
       " 0.9375645807302999,\n",
       " array([[115679,   1249],\n",
       "        [  1821,  10396]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_clf = CatBoostClassifier(\n",
    "    iterations=5000,\n",
    "    learning_rate=0.03,\n",
    "    depth=8,\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    random_seed=42,\n",
    "    verbose=200,\n",
    ")\n",
    "\n",
    "cat_clf.fit(\n",
    "    X_train_cb,\n",
    "    y_train,\n",
    "    eval_set=(X_valid_cb, y_valid),\n",
    "    cat_features=cat_col_idx,\n",
    "    use_best_model=True,\n",
    "    early_stopping_rounds=200,\n",
    ")\n",
    "\n",
    "p_valid_cat = cat_clf.predict_proba(X_valid_cb)[:, 1]\n",
    "p_test_cat  = cat_clf.predict_proba(X_test_cb)[:, 1]\n",
    "\n",
    "eval_binary(y_valid, p_valid_cat, prefix=\"[CAT valid] \")\n",
    "eval_binary(y_test,  p_test_cat,  prefix=\"[CAT test ] \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9126d392",
   "metadata": {},
   "source": [
    "# RandomForest 학습/평가 (sparse 그대로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8fd00ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF valid] ROC-AUC: 0.984179 | PR-AUC(AP): 0.905187 | thr=0.5\n",
      "[RF valid] Confusion matrix:\n",
      "[[112999   3929]\n",
      " [  1146  11071]]\n",
      "[RF valid] Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9900    0.9664    0.9780    116928\n",
      "           1     0.7381    0.9062    0.8135     12217\n",
      "\n",
      "    accuracy                         0.9607    129145\n",
      "   macro avg     0.8640    0.9363    0.8958    129145\n",
      "weighted avg     0.9661    0.9607    0.9625    129145\n",
      "\n",
      "[RF test ] ROC-AUC: 0.984798 | PR-AUC(AP): 0.909327 | thr=0.5\n",
      "[RF test ] Confusion matrix:\n",
      "[[113056   3872]\n",
      " [  1166  11051]]\n",
      "[RF test ] Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9898    0.9669    0.9782    116928\n",
      "           1     0.7405    0.9046    0.8144     12217\n",
      "\n",
      "    accuracy                         0.9610    129145\n",
      "   macro avg     0.8652    0.9357    0.8963    129145\n",
      "weighted avg     0.9662    0.9610    0.9627    129145\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9847984648439577,\n",
       " 0.9093271047018638,\n",
       " array([[113056,   3872],\n",
       "        [  1166,  11051]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=600,              # 너무 크게 잡으면 오래 걸림\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=50,           # 과적합/시간 둘 다 완화\n",
    "    min_samples_split=100,\n",
    "    max_features=\"sqrt\",\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced_subsample\",\n",
    ")\n",
    "\n",
    "rf.fit(X_train_t, y_train)\n",
    "\n",
    "p_valid_rf = rf.predict_proba(X_valid_t)[:, 1]\n",
    "p_test_rf  = rf.predict_proba(X_test_t)[:, 1]\n",
    "\n",
    "eval_binary(y_valid, p_valid_rf, prefix=\"[RF valid] \")\n",
    "eval_binary(y_test,  p_test_rf,  prefix=\"[RF test ] \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22e1c34",
   "metadata": {},
   "source": [
    "# Ensemble (CatBoost + LightGBM) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63c33d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_cat</th>\n",
       "      <th>w_lgbm</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>ap</th>\n",
       "      <th>precision@0.5</th>\n",
       "      <th>recall@0.5</th>\n",
       "      <th>f1@0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.989052</td>\n",
       "      <td>0.934471</td>\n",
       "      <td>0.869919</td>\n",
       "      <td>0.865433</td>\n",
       "      <td>0.867671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.989049</td>\n",
       "      <td>0.934469</td>\n",
       "      <td>0.871776</td>\n",
       "      <td>0.863142</td>\n",
       "      <td>0.867437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.989053</td>\n",
       "      <td>0.934468</td>\n",
       "      <td>0.867271</td>\n",
       "      <td>0.869117</td>\n",
       "      <td>0.868193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.775</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.989053</td>\n",
       "      <td>0.934460</td>\n",
       "      <td>0.865258</td>\n",
       "      <td>0.871491</td>\n",
       "      <td>0.868363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.989041</td>\n",
       "      <td>0.934459</td>\n",
       "      <td>0.874303</td>\n",
       "      <td>0.860277</td>\n",
       "      <td>0.867233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.989051</td>\n",
       "      <td>0.934448</td>\n",
       "      <td>0.862476</td>\n",
       "      <td>0.873701</td>\n",
       "      <td>0.868052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.989028</td>\n",
       "      <td>0.934440</td>\n",
       "      <td>0.877385</td>\n",
       "      <td>0.858067</td>\n",
       "      <td>0.867618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.989049</td>\n",
       "      <td>0.934434</td>\n",
       "      <td>0.859469</td>\n",
       "      <td>0.877057</td>\n",
       "      <td>0.868174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.989046</td>\n",
       "      <td>0.934415</td>\n",
       "      <td>0.856881</td>\n",
       "      <td>0.879676</td>\n",
       "      <td>0.868129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.989007</td>\n",
       "      <td>0.934408</td>\n",
       "      <td>0.879865</td>\n",
       "      <td>0.854874</td>\n",
       "      <td>0.867190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    w_cat  w_lgbm   roc_auc        ap  precision@0.5  recall@0.5    f1@0.5\n",
       "33  0.825   0.175  0.989052  0.934471       0.869919    0.865433  0.867671\n",
       "34  0.850   0.150  0.989049  0.934469       0.871776    0.863142  0.867437\n",
       "32  0.800   0.200  0.989053  0.934468       0.867271    0.869117  0.868193\n",
       "31  0.775   0.225  0.989053  0.934460       0.865258    0.871491  0.868363\n",
       "35  0.875   0.125  0.989041  0.934459       0.874303    0.860277  0.867233\n",
       "30  0.750   0.250  0.989051  0.934448       0.862476    0.873701  0.868052\n",
       "36  0.900   0.100  0.989028  0.934440       0.877385    0.858067  0.867618\n",
       "29  0.725   0.275  0.989049  0.934434       0.859469    0.877057  0.868174\n",
       "28  0.700   0.300  0.989046  0.934415       0.856881    0.879676  0.868129\n",
       "37  0.925   0.075  0.989007  0.934408       0.879865    0.854874  0.867190"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_w_cat(valid): 0.8250000000000001\n",
      "[ENS valid w_cat=0.825] ROC-AUC: 0.989052 | PR-AUC(AP): 0.934471 | thr=0.5\n",
      "[ENS valid w_cat=0.825] Confusion matrix:\n",
      "[[115347   1581]\n",
      " [  1644  10573]]\n",
      "[ENS valid w_cat=0.825] Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9859    0.9865    0.9862    116928\n",
      "           1     0.8699    0.8654    0.8677     12217\n",
      "\n",
      "    accuracy                         0.9750    129145\n",
      "   macro avg     0.9279    0.9260    0.9269    129145\n",
      "weighted avg     0.9750    0.9750    0.9750    129145\n",
      "\n",
      "[ENS test  w_cat=0.825] ROC-AUC: 0.989473 | PR-AUC(AP): 0.937834 | thr=0.5\n",
      "[ENS test  w_cat=0.825] Confusion matrix:\n",
      "[[115438   1490]\n",
      " [  1616  10601]]\n",
      "[ENS test  w_cat=0.825] Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9862    0.9873    0.9867    116928\n",
      "           1     0.8768    0.8677    0.8722     12217\n",
      "\n",
      "    accuracy                         0.9759    129145\n",
      "   macro avg     0.9315    0.9275    0.9295    129145\n",
      "weighted avg     0.9758    0.9759    0.9759    129145\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9894727239788168,\n",
       " 0.9378343019430334,\n",
       " array([[115438,   1490],\n",
       "        [  1616,  10601]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Ensemble (CatBoost + LightGBM) ===\n",
    "# 전제: p_valid_cat, p_test_cat, p_valid_lgbm, p_test_lgbm 이미 있음\n",
    "#       y_valid, y_test, eval_binary() 이미 있음\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_fscore_support\n",
    "\n",
    "def sweep_ensemble_weights(\n",
    "    y_true,\n",
    "    p_cat,\n",
    "    p_lgbm,\n",
    "    weights=np.linspace(0.0, 1.0, 21),  # cat weight\n",
    "):\n",
    "    rows = []\n",
    "    for w in weights:\n",
    "        p = w * p_cat + (1 - w) * p_lgbm\n",
    "        roc = roc_auc_score(y_true, p)\n",
    "        ap = average_precision_score(y_true, p)\n",
    "\n",
    "        # 기본 thr=0.5에서 precision/recall/f1도 같이 기록\n",
    "        y_pred = (p >= 0.5).astype(int)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average=\"binary\", zero_division=0\n",
    "        )\n",
    "\n",
    "        rows.append({\n",
    "            \"w_cat\": float(w),\n",
    "            \"w_lgbm\": float(1 - w),\n",
    "            \"roc_auc\": float(roc),\n",
    "            \"ap\": float(ap),\n",
    "            \"precision@0.5\": float(prec),\n",
    "            \"recall@0.5\": float(rec),\n",
    "            \"f1@0.5\": float(f1),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values([\"ap\", \"roc_auc\"], ascending=False)\n",
    "\n",
    "# 1) valid에서 가중치 스윕\n",
    "ens_valid_df = sweep_ensemble_weights(\n",
    "    y_valid, p_valid_cat, p_valid_lgbm,\n",
    "    weights=np.linspace(0.0, 1.0, 41)  # 0.025 간격\n",
    ")\n",
    "display(ens_valid_df.head(10))\n",
    "\n",
    "best_w = float(ens_valid_df.iloc[0][\"w_cat\"])\n",
    "print(\"best_w_cat(valid):\", best_w)\n",
    "\n",
    "# 2) best weight로 valid/test 평가 (thr=0.5)\n",
    "p_valid_ens = best_w * p_valid_cat + (1 - best_w) * p_valid_lgbm\n",
    "p_test_ens  = best_w * p_test_cat  + (1 - best_w) * p_test_lgbm\n",
    "\n",
    "eval_binary(y_valid, p_valid_ens, prefix=f\"[ENS valid w_cat={best_w:.3f}] \")\n",
    "eval_binary(y_test,  p_test_ens,  prefix=f\"[ENS test  w_cat={best_w:.3f}] \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150e4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-2nd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
