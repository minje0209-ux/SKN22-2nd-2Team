{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier Baseline (Model Comparison) v3\n",
    "\n",
    "- 모델 종류 체급 비교 목적\n",
    "\n",
    "평가 (Test set):\n",
    "- PR-AUC\n",
    "- Recall (Churn)\n",
    "- Accuracy\n",
    "- Confusion Matrix\n",
    "- Classification Report\n",
    "- Feature Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/kkbox_train_feature_v3.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 719\n",
    "\n",
    "ID_COL = \"msno\"\n",
    "TARGET_COL = \"is_churn\"\n",
    "\n",
    "CATEGORICAL_COLS = [\n",
    "    \"city\",\n",
    "    \"gender\",\n",
    "    \"registered_via\",\n",
    "    \"last_payment_method\",\n",
    "    \"has_ever_paid\",\n",
    "    \"has_ever_cancelled\",\n",
    "    # \"is_auto_renew_last\",\n",
    "    \"is_free_user\",\n",
    "]\n",
    "\n",
    "NUMERICAL_COLS = [\n",
    "    # \"reg_days\",\n",
    "    \"num_days_active_w7\",\n",
    "    \"total_secs_w7\",\n",
    "    \"avg_secs_per_day_w7\",\n",
    "    \"std_secs_w7\",\n",
    "    \"num_songs_w7\",\n",
    "    \"avg_songs_per_day_w7\",\n",
    "    \"num_unq_w7\",\n",
    "    \"num_25_w7\",\n",
    "    \"num_100_w7\",\n",
    "    \"short_play_w7\",\n",
    "    \"skip_ratio_w7\",\n",
    "    \"completion_ratio_w7\",\n",
    "    \"short_play_ratio_w7\",\n",
    "    \"variety_ratio_w7\",\n",
    "    \"num_days_active_w14\",\n",
    "    \"total_secs_w14\",\n",
    "    \"avg_secs_per_day_w14\",\n",
    "    \"std_secs_w14\",\n",
    "    \"num_songs_w14\",\n",
    "    \"avg_songs_per_day_w14\",\n",
    "    \"num_unq_w14\",\n",
    "    \"num_25_w14\",\n",
    "    \"num_100_w14\",\n",
    "    \"short_play_w14\",\n",
    "    \"skip_ratio_w14\",\n",
    "    \"completion_ratio_w14\",\n",
    "    \"short_play_ratio_w14\",\n",
    "    \"variety_ratio_w14\",\n",
    "    \"num_days_active_w21\",\n",
    "    \"total_secs_w21\",\n",
    "    \"avg_secs_per_day_w21\",\n",
    "    \"std_secs_w21\",\n",
    "    \"num_songs_w21\",\n",
    "    \"avg_songs_per_day_w21\",\n",
    "    \"num_unq_w21\",\n",
    "    \"num_25_w21\",\n",
    "    \"num_100_w21\",\n",
    "    \"short_play_w21\",\n",
    "    \"skip_ratio_w21\",\n",
    "    \"completion_ratio_w21\",\n",
    "    \"short_play_ratio_w21\",\n",
    "    \"variety_ratio_w21\",\n",
    "    \"num_days_active_w30\",\n",
    "    \"total_secs_w30\",\n",
    "    \"avg_secs_per_day_w30\",\n",
    "    \"std_secs_w30\",\n",
    "    \"num_songs_w30\",\n",
    "    \"avg_songs_per_day_w30\",\n",
    "    \"num_unq_w30\",\n",
    "    \"num_25_w30\",\n",
    "    \"num_100_w30\",\n",
    "    \"short_play_w30\",\n",
    "    \"skip_ratio_w30\",\n",
    "    \"completion_ratio_w30\",\n",
    "    \"short_play_ratio_w30\",\n",
    "    \"variety_ratio_w30\",\n",
    "    \"secs_trend_w7_w30\",\n",
    "    \"secs_trend_w14_w30\",\n",
    "    \"days_trend_w7_w14\",\n",
    "    \"days_trend_w7_w30\",\n",
    "    \"songs_trend_w7_w30\",\n",
    "    \"songs_trend_w14_w30\",\n",
    "    \"skip_trend_w7_w30\",\n",
    "    \"completion_trend_w7_w30\",\n",
    "    # \"days_since_last_payment\",\n",
    "    # \"days_since_last_cancel\",\n",
    "    \"last_plan_days\",\n",
    "    \"total_payment_count\",\n",
    "    \"total_amount_paid\",\n",
    "    \"avg_amount_per_payment\",\n",
    "    \"unique_plan_count\",\n",
    "    \"subscription_months_est\",\n",
    "    \"payment_count_last_30d\",\n",
    "    \"payment_count_last_90d\",\n",
    "]\n",
    "\n",
    "FEATURE_COLS = CATEGORICAL_COLS + NUMERICAL_COLS\n",
    "\n",
    "X = df[FEATURE_COLS].copy()\n",
    "y = df[TARGET_COL].astype(int).copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train / Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(688772, 79) (172194, 79)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[FEATURE_COLS]\n",
    "y = df[TARGET_COL].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Column Groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cols: 72\n",
      "cat_cols: 7\n"
     ]
    }
   ],
   "source": [
    "cat_cols = [c for c in CATEGORICAL_COLS if c in X_train.columns]\n",
    "num_cols = [c for c in NUMERICAL_COLS if c in X_train.columns]\n",
    "\n",
    "print(f\"num_cols: {len(num_cols)}\")\n",
    "print(f\"cat_cols: {len(cat_cols)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6a982",
   "metadata": {},
   "source": [
    "## 3. Preprocessing (OHE only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35c9fa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "X_train_t = preprocess.fit_transform(X_train)\n",
    "X_test_t = preprocess.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a181aaf",
   "metadata": {},
   "source": [
    "## 4. Random Forest Classifier Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "696866a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=800,\n",
    "    max_depth=None,\n",
    "    max_features=\"sqrt\",\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd30ef8e",
   "metadata": {},
   "source": [
    "## 5. Train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.fit(X_train_t, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b089334",
   "metadata": {},
   "source": [
    "## 6. Test Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f931a96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     average_precision_score,\n\u001b[32m      5\u001b[39m     recall_score,\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     classification_report,\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m y_proba = \u001b[43mrf_model\u001b[49m.predict_proba(X_test_t)[:, \u001b[32m1\u001b[39m]\n\u001b[32m     12\u001b[39m y_pred  = rf_model.predict(X_test_t)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPR-AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maverage_precision_score(y_test,\u001b[38;5;250m \u001b[39my_proba)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'rf_model' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "y_proba = rf_model.predict_proba(X_test_t)[:, 1]\n",
    "y_pred  = rf_model.predict(X_test_t)\n",
    "\n",
    "print(f\"PR-AUC: {average_precision_score(y_test, y_proba):.4f}\")\n",
    "print(f\"Recall (Churn): {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f939234c",
   "metadata": {},
   "source": [
    "## 7. Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9528a1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 0</th>\n",
       "      <th>Pred 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>154317</td>\n",
       "      <td>1587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>3072</td>\n",
       "      <td>13218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred 0  Pred 1\n",
       "Actual 0  154317    1587\n",
       "Actual 1    3072   13218"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Pred 0\", \"Pred 1\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e08b45",
   "metadata": {},
   "source": [
    "## 8. Classification Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e9fdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9805    0.9898    0.9851    155904\n",
      "           1     0.8928    0.8114    0.8502     16290\n",
      "\n",
      "    accuracy                         0.9729    172194\n",
      "   macro avg     0.9366    0.9006    0.9176    172194\n",
      "weighted avg     0.9722    0.9729    0.9724    172194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bba899",
   "metadata": {},
   "source": [
    "## 9. Feature Importance (Impurity Decrease)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a350800",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = preprocess.get_feature_names_out()\n",
    "importances = rf_model.feature_importances_\n",
    "\n",
    "imp_rf_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": importances,\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "imp_rf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca47890b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m cm = confusion_matrix(\u001b[43my_test\u001b[49m, y_pred)\n\u001b[32m      7\u001b[39m sns.heatmap(cm, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, fmt=\u001b[33m'\u001b[39m\u001b[33md\u001b[39m\u001b[33m'\u001b[39m, cmap=\u001b[33m'\u001b[39m\u001b[33mBlues\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mPredicted\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp_rf_df.to_csv(\n",
    "#     \"../data/model_df/rf_feature_importance.csv\",\n",
    "#     index=False\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-2nd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
